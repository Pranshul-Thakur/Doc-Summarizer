{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6169cc47-a314-4feb-a336-d9137ccae634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from typing import List\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import Tool, initialize_agent, AgentType\n",
    "from langchain.schema import Document\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8012337-1f5a-4289-bd3d-41e32b607267",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash-latest\",\n",
    "    temperature=0,\n",
    "    google_api_key=\"API KEY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e919aefa-eb9c-4f4a-b3d3-48a436f7bddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_96056\\1094393795.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  EMBEDDINGS = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "EMBEDDINGS = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "124c4d72-39b4-499f-b928-700a9c009713",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_DIR = \"./vector_store\"\n",
    "RAG_COLLECTION = \"research_rag\"\n",
    "MEM_COLLECTION = \"long_term_memory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bb1bd3e-d04e-461c-ad11-c7187208e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_docs(raw_docs: List[Document]) -> List[Document]:\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "    return splitter.split_documents(raw_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b3ca44-8a5a-4707-a9d1-998d8924ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PDF_to_docs(fp: str) -> List[Document]:\n",
    "    return split_docs(PyPDFLoader(fp).load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "256ae0b9-7ff8-4a1d-9121-115f12b3fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DOCX_to_docs(fp: str) -> List[Document]:\n",
    "    return split_docs(Docx2txtLoader(fp).load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "060a7112-7f8a-4e10-a254-f699e8a4776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs(path: str) -> List[Document]:\n",
    "    docs = []\n",
    "    if os.path.isfile(path):\n",
    "        if path.lower().endswith(\".pdf\"):\n",
    "            docs.extend(PDF_to_docs(path))\n",
    "        elif path.lower().endswith((\".docx\", \".doc\")):\n",
    "            docs.extend(DOCX_to_docs(path))\n",
    "    else:\n",
    "        for root, _, files in os.walk(path):\n",
    "            for f in files:\n",
    "                fp = os.path.join(root, f)\n",
    "                if f.lower().endswith(\".pdf\"):\n",
    "                    docs.extend(PDF_to_docs(fp))\n",
    "                elif f.lower().endswith((\".docx\", \".doc\")):\n",
    "                    docs.extend(DOCX_to_docs(fp))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01665304-17c9-4e08-aff4-1943421bc52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_or_load_vs(collection: str) -> Chroma:\n",
    "    return Chroma(collection_name=collection, embedding_function=EMBEDDINGS, persist_directory=CHROMA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2abd043-4296-4650-b851-179ca40c7d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_write(text: str):\n",
    "    vs = build_or_load_vs(MEM_COLLECTION)\n",
    "    vs.add_texts([text])\n",
    "    vs.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d03cc24f-8a21-4146-b6ac-739afe7c6d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_search(query: str, k: int = 5) -> List[str]:\n",
    "    vs = build_or_load_vs(MEM_COLLECTION)\n",
    "    return [d.page_content for d in vs.similarity_search(query, k=k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5fa13b5-9271-4687-bee2-8bfb0a7098fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_retriever():\n",
    "    return build_or_load_vs(RAG_COLLECTION).as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "014f6253-b8ac-4386-b46c-4c17d9793e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_retrieve(query: str) -> str:\n",
    "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=rag_retriever(), return_source_documents=True)\n",
    "    out = chain({\"query\": query})\n",
    "    ans = out[\"result\"]\n",
    "    sources = \"\\n\".join({d.metadata.get(\"source\", \"unknown\") for d in out[\"source_documents\"]})\n",
    "    return f\"Answer: {ans}\\n\\nSources:\\n{sources}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81a45c24-c379-49c7-97da-b619d5b4752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_summarize(path: str) -> str:\n",
    "    docs = PDF_to_docs(path) if path.lower().endswith(\".pdf\") else DOCX_to_docs(path)\n",
    "    chunks = [d.page_content for d in docs]\n",
    "    summaries = []\n",
    "    for i in range(0, len(chunks), 6):\n",
    "        part = \"\\n\\n\".join(chunks[i:i+6])\n",
    "        resp = llm.invoke([(\"system\", \"Summarize in bullet points <=120 words\"), (\"user\", part[:6000])])\n",
    "        summaries.append(resp.content)\n",
    "    final_resp = llm.invoke([(\"system\", \"Combine into one <=200 words\"), (\"user\", \"\\n\\n\".join(summaries)[:6000])])\n",
    "    return final_resp.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbd0356b-fe2b-4fe0-a185-de432f50984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_memory_write(text: str) -> str:\n",
    "    memory_write(text)\n",
    "    return \"Saved to long-term memory.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60a76ce7-2630-4c1e-8230-a778ef005489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_memory_search(query: str) -> str:\n",
    "    hits = memory_search(query)\n",
    "    return \"\\n- \".join([\"Memories:\"] + hits) if hits else \"No memory found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53ed7723-69f9-4cc5-900a-df5c4417b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_agent():\n",
    "    tools = [\n",
    "        Tool(name=\"retrieve\", func=tool_retrieve, description=\"Answer research questions from indexed docs\"),\n",
    "        Tool(name=\"summarize_file\", func=tool_summarize, description=\"Summarize a PDF/DOC file\"),\n",
    "        Tool(name=\"memory_write\", func=tool_memory_write, description=\"Store a note in long-term memory\"),\n",
    "        Tool(name=\"memory_search\", func=tool_memory_search, description=\"Search notes in long-term memory\"),\n",
    "    ]\n",
    "    return initialize_agent(tools=tools, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c321ab86-fb25-4741-bd48-bd64a513da8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest(path: str):\n",
    "    docs = load_docs(path)\n",
    "    vs = build_or_load_vs(RAG_COLLECTION)\n",
    "    vs.add_texts([d.page_content for d in docs], metadatas=[d.metadata for d in docs])\n",
    "    vs.persist()\n",
    "    print(f\"Ingested {len(docs)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3de5950-beb8-4792-b41a-5d8ca00f2cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_cli():\n",
    "    agent = make_agent()\n",
    "    print(\"Type 'exit' to quit.\")\n",
    "    while True:\n",
    "        q = input(\"You: \")\n",
    "        if q.strip().lower() in {\"exit\", \"quit\"}:\n",
    "            break\n",
    "        try:\n",
    "            print(agent.run(q))\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e8b9a35-f2ff-492f-a8aa-8050978c04b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_cli(path: str):\n",
    "    print(tool_summarize(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71b49f52-fc4f-4ac8-820d-ab1a7037f998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingested 36 chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_96056\\3604251944.py:5: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vs.persist()\n"
     ]
    }
   ],
   "source": [
    "ingest(\"C:\\\\Users\\\\LENOVO\\\\Desktop\\\\new\\\\main\\\\App\\\\Research_paper.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c3a4f34-b74f-4bb5-9b26-379558bf5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "def summarize_docs() -> str:\n",
    "    vs = build_or_load_vs(RAG_COLLECTION)  # load your ingested vector store\n",
    "    chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=vs.as_retriever(search_kwargs={\"k\": 5}),\n",
    "        chain_type=\"stuff\"\n",
    "    )\n",
    "    return chain.run(\"Summarize the ingested document in detail.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0aef8c77-ba5b-4ded-9c51-dc030bfe903c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_96056\\1624136186.py:10: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  return chain.run(\"Summarize the ingested document in detail.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This document discusses the application of deep learning (DL) in healthcare, focusing on challenges and opportunities, particularly in the context of rare diseases.  It highlights the need for interpretable DL models, especially when dealing with small datasets, high class imbalance, and limited external validation data, common issues in rare disease research.\n",
      "\n",
      "The text mentions that attention mechanisms within DL models offer a built-in interpretability advantage by dynamically weighting features during training, improving both transparency and performance in healthcare applications.  Several research papers are cited which explore these topics, including:\n",
      "\n",
      "*   **Lee et al. [4]:** Emphasizes the need for interpretable DL models in low-data scenarios.\n",
      "*   **Abdar et al. [25]:** Highlights techniques like reweighting and uncertainty quantification to address class imbalance in DL workflows.\n",
      "*   **Esteva et al. [13]:** Provides a guide to deep learning in healthcare.\n",
      "*   **Lundberg and Lee [14]:** Presents a unified approach to interpreting model predictions.\n",
      "*   **Caruana et al. [15]:** Focuses on intelligible models for healthcare, predicting pneumonia risk and hospital readmission.\n",
      "*   **Che et al. [16]:** Discusses interpretable deep models for ICU outcome prediction.\n",
      "*   **Chen and Guestrin [17]:**  (Partial citation, full context missing) mentions XGBoost.\n",
      "*   **Janowczyk and Madabhushi [27]:** Covers deep learning for digital pathology image analysis.\n",
      "*   **Miotto et al. [28]:** Reviews deep learning for healthcare, outlining opportunities and challenges.\n",
      "\n",
      "A further point is made about a study where an ensemble model combining predictions from top traditional classifiers performed best for medical event prediction.  Finally, a Github link ([29]) is provided, presumably to related project code.  The overall theme is the advancement and challenges of using deep learning for improved healthcare, with a particular focus on interpretability and handling data limitations inherent in rare disease research.\n"
     ]
    }
   ],
   "source": [
    "summary = summarize_docs()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3874b4d-8214-4cc4-ac2e-2002023f64ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
